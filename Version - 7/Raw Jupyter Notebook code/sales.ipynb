{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17325eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3c15a025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    0\n",
      "TV            0\n",
      "Radio         0\n",
      "Newspaper     0\n",
      "Sales         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#this is the most basic model\n",
    "#importing the dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('Advertising.csv')\n",
    "print(data.isna().sum())\n",
    "\n",
    "X = data[['TV', 'Radio', 'Newspaper']].values\n",
    "y = data['Sales'].values.reshape(-1, 1)\n",
    "\n",
    "TV = X[:, 0].reshape(-1, 1)\n",
    "Radio = X[:, 1].reshape(-1, 1)\n",
    "Newspaper = X[:, 2].reshape(-1, 1)\n",
    "\n",
    "\n",
    "X_poly = np.hstack([\n",
    "    TV,\n",
    "    Radio,\n",
    "    Newspaper,\n",
    "    TV**2,\n",
    "    Radio**2,\n",
    "    Newspaper**2,\n",
    "    TV*Radio,\n",
    "    TV*Newspaper,\n",
    "    Radio*Newspaper\n",
    "])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_poly, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "#calculating mean and std for normalization\n",
    "\n",
    "X_mean = X_train.mean(axis=0)\n",
    "X_std = X_train.std(axis=0)\n",
    "\n",
    "#normalizing the data\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "\n",
    "y_train_mean = y_train.mean()\n",
    "y_train_std = y_train.std()\n",
    "y_train = (y_train - y_train_mean) / y_train_std\n",
    "y_test = (y_test - y_train_mean) / y_train_std\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec9bd19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the bias term\n",
    "\n",
    "#import numpy as np\n",
    "\n",
    "#expanded_X = np.ones((X.shape[0], 1))\n",
    "#X_b = np.c_[expanded_X, X]\n",
    "#X_b will have the bias term added to the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0a096ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding the  linear regression model from scratch\n",
    "\n",
    "class LinearRegression:\n",
    "\n",
    "    def __init__(self, learn_rate = 1e-7, iter = 50000, method = 'batch', batch_size = 32, l1_reg = 0.0):\n",
    "        self.l1_reg = l1_reg\n",
    "        self.method = method\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = float(learn_rate)\n",
    "        self.iter = int(iter)\n",
    "        self.weights = None\n",
    "        self.loss_history = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        #m -- no of samples (north to south)\n",
    "        #n -- no of features (west to east)\n",
    "\n",
    "        self.weights = np.zeros((n, 1))\n",
    "        #initializing weights to zero including bias term\n",
    "        self.bias = 0\n",
    "\n",
    "\n",
    "        for _ in range(self.iter):\n",
    "            if self.method == 'batch':\n",
    "\n",
    "                y_pred = X @ self.weights + self.bias\n",
    "                error = y_pred - y\n",
    "                loss = (1/(2*m)) * np.sum(error ** 2) + (self.l1_reg/2) * np.sum(np.abs(self.weights))\n",
    "\n",
    "                grad_w = (1/m) * (X.T @ error) + self.l1_reg * np.sign(self.weights)\n",
    "                grad_b = (1/m) * np.sum(error)\n",
    "                #loss gradients wrt to weights and bias\n",
    "\n",
    "                self.weights -= self.lr * grad_w\n",
    "                self.bias -= self.lr * grad_b\n",
    "\n",
    "            elif self.method == 'stochastic':\n",
    "                for i in range(m):\n",
    "                    xi = X[i].reshape(1, -1)\n",
    "                    yi = y[i].reshape(1, -1)\n",
    "                    y_pred = xi @ self.weights + self.bias\n",
    "                    error = y_pred - yi\n",
    "\n",
    "                    gradient_w = xi.T @ error\n",
    "                    gradient_b = error.item()\n",
    "\n",
    "                    self.weights -= self.lr * gradient_w\n",
    "                    self.bias -= self.lr * gradient_b\n",
    "\n",
    "                y_pred = X @ self.weights + self.bias\n",
    "                loss = (1/(2*m)) * np.sum((y_pred - y) ** 2) + (self.l1_reg/2) * np.sum(np.abs(self.weights))\n",
    "                #this is the loss after one epoch\n",
    "\n",
    "            elif self.method == 'mini-batch':\n",
    "                premu = np.random.permutation(m)\n",
    "                X_Shuffle = X[premu]\n",
    "                y_Shuffle = y[premu]\n",
    "\n",
    "                for start in range(0, m, self.batch_size):\n",
    "                    end = start + self.batch_size\n",
    "                    xb = X_Shuffle[start:end]\n",
    "                    yb = y_Shuffle[start:end]\n",
    "\n",
    "                    y_pred = xb @ self.weights + self.bias\n",
    "                    error = y_pred - yb\n",
    "\n",
    "                    gradient_w = (1/self.batch_size) * (xb.T @ error)\n",
    "                    gradient_b = (1/self.batch_size) * np.sum(error)\n",
    "\n",
    "                    self.weights -= self.lr * gradient_w\n",
    "                    self.bias -= self.lr * gradient_b\n",
    "                \n",
    "                #calculating loss after one epoch\n",
    "                y_pred  = X @self.weights + self.bias\n",
    "                error = y_pred - y\n",
    "                loss = (1/(2*m)) * np.sum(error ** 2) + (self.l1_reg/2) * np.sum(np.abs(self.weights))\n",
    "\n",
    "        \n",
    "            self.loss_history.append(loss)\n",
    "\n",
    "           \n",
    "            if _ % 5000 == 0:\n",
    "                print(f\"Loss at iteration {_}: {loss}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X @ self.weights + self.bias\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d5269520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0: 0.49999999999999983\n",
      "Loss at iteration 5000: 0.07141533218904708\n",
      "Loss at iteration 10000: 0.07145543979123073\n",
      "Loss at iteration 15000: 0.071420163081333\n",
      "Loss at iteration 20000: 0.07136202751948267\n",
      "Loss at iteration 25000: 0.07142164650332272\n",
      "Loss at iteration 30000: 0.07130587031901772\n",
      "Loss at iteration 35000: 0.0714030518820292\n",
      "Loss at iteration 40000: 0.07134685635484242\n",
      "Loss at iteration 45000: 0.07130973429793122\n",
      "Mean Squared Error: 0.050595790198221566\n",
      "Root Mean Squared Error: 0.22493507996357875\n",
      "Mean Absolute Error: 0.15327988576577836\n",
      "R^2 Score on test set: 0.958424725843247\n",
      "R^2 Score on training set: 0.950938035826986\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(learn_rate= 0.02, iter=50000, method='batch', l1_reg=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions_on_test = model.predict(X_test)\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "\n",
    "mse = np.mean((predictions_on_test - y_test) ** 2)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "\n",
    "mae = np.mean(np.abs(predictions_on_test - y_test))\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "ss_res = np.sum((y_test - predictions_on_test) ** 2)\n",
    "sst_tot = np.sum((y_test - np.mean(y_test))** 2 )\n",
    "r2_score = 1 - (ss_res / sst_tot)\n",
    "print(\"R^2 Score on test set:\", r2_score)\n",
    "\n",
    "#r2 score on training set\n",
    "ss_res_train = np.sum((y_train - train_predictions) ** 2)\n",
    "sst_tot_train = np.sum((y_train - np.mean(y_train))** 2 )\n",
    "r2_score_train = 1 - (ss_res_train / sst_tot_train)\n",
    "print(\"R^2 Score on training set:\", r2_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c99f3192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.loss_history)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Convergence\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "050f2356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0: 0.16690690672817432\n",
      "Mean Squared Error with SGD: 0.01827396878994053\n",
      "Mean Absolute Error with SGD: 0.11180636071639252\n",
      "Root Mean Squared Error with SGD: 0.13518124422396965\n",
      "R^2 Score on test set with SGD: 0.9849840222003208\n",
      "R^2 Score on training set with SGD: 0.9848117061887512\n"
     ]
    }
   ],
   "source": [
    "#examining stochastic gradient descent\n",
    "model_sgd = LinearRegression(learn_rate= 0.01, iter=50, method='stochastic', l1_reg=0.2)\n",
    "model_sgd.fit(X_train, y_train)\n",
    "predictions_on_test = model_sgd.predict(X_test)\n",
    "\n",
    "prediction_on_train = model_sgd.predict(X_train)\n",
    "\n",
    "mse_on_sgd = np.mean((predictions_on_test - y_test) ** 2)\n",
    "print(\"Mean Squared Error with SGD:\", mse_on_sgd)\n",
    "\n",
    "mae_on_sgd = np.mean(np.abs(predictions_on_test - y_test))\n",
    "print(\"Mean Absolute Error with SGD:\", mae_on_sgd)\n",
    "\n",
    "rmse_on_sgd = np.sqrt(mse_on_sgd)\n",
    "print(\"Root Mean Squared Error with SGD:\", rmse_on_sgd)\n",
    "\n",
    "ss_res_sgd = np.sum((y_test - predictions_on_test) ** 2)\n",
    "sst_tot_sgd = np.sum((y_test - np.mean(y_test))** 2)\n",
    "r2_score_on_sgd = 1 - (ss_res_sgd / sst_tot_sgd)\n",
    "print(\"R^2 Score on test set with SGD:\", r2_score_on_sgd)\n",
    "\n",
    "ss_res_train_sgd = np.sum((y_train - prediction_on_train) ** 2)\n",
    "sst_tot_train_sgd = np.sum((y_train - np.mean(y_train))**2)\n",
    "r2_score_train_sgd = 1 - (ss_res_train_sgd / sst_tot_train_sgd)\n",
    "print(\"R^2 Score on training set with SGD:\", r2_score_train_sgd)\n",
    "\n",
    "                           \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "819a6959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0: 0.2931786522739655\n",
      "Mean Squared Error with Mini-Batch GD: 0.013978848457933523\n",
      "Root Mean Squared Error with Mini-Batch GD: 0.11823218029763945\n",
      "Mean Absolute Error with Mini-Batch GD: 0.07866607715618698\n",
      "R^2 Score on training set with Mini-Batch GD: 0.9860211515420665\n",
      "Mean Squared Error on test set with Mini-Batch GD: 0.015296536612991124\n",
      "Root Mean Squared Error on test set with Mini-Batch GD: 0.12367916806395135\n",
      "Mean Absolute Error on test set with Mini-Batch GD: 0.1008713358075977\n",
      "R^2 Score on test set with Mini-Batch GD: 0.9874306201989851\n"
     ]
    }
   ],
   "source": [
    "#examining mini-batch gradient descent\n",
    "model_mini = LinearRegression(learn_rate= 0.01, iter=1000, method='mini-batch', batch_size=16, l1_reg=0.15)\n",
    "model_mini.fit(X_train, y_train)\n",
    "predictions_on_test = model_mini.predict(X_test)\n",
    "\n",
    "prediction_on_train = model_mini.predict(X_train)\n",
    "\n",
    "mse_on_mini_train = np.mean((prediction_on_train - y_train)**2)\n",
    "print(\"Mean Squared Error with Mini-Batch GD:\", mse_on_mini_train)\n",
    "\n",
    "rmse_on_mini_train = np.sqrt(mse_on_mini_train)\n",
    "print(\"Root Mean Squared Error with Mini-Batch GD:\", rmse_on_mini_train)\n",
    "\n",
    "mae_on_mini_train = np.mean(np.abs(prediction_on_train - y_train))\n",
    "print(\"Mean Absolute Error with Mini-Batch GD:\", mae_on_mini_train)\n",
    "\n",
    "ss_res_mini_train = np.sum((y_train - prediction_on_train) ** 2)\n",
    "sst_tot_mini_train = np.sum((y_train - np.mean(y_train))**2)\n",
    "r2_score_on_mini_train = 1 - (ss_res_mini_train / sst_tot_mini_train)\n",
    "print(\"R^2 Score on training set with Mini-Batch GD:\", r2_score_on_mini_train)\n",
    "\n",
    "mse_on_mini_test = np.mean((predictions_on_test - y_test) ** 2) \n",
    "print(\"Mean Squared Error on test set with Mini-Batch GD:\", mse_on_mini_test)\n",
    "\n",
    "rmse_on_mini_test = np.sqrt(mse_on_mini_test)\n",
    "print(\"Root Mean Squared Error on test set with Mini-Batch GD:\", rmse_on_mini_test)\n",
    "\n",
    "mae_on_mini_test = np.mean(np.abs(predictions_on_test - y_test))\n",
    "print(\"Mean Absolute Error on test set with Mini-Batch GD:\", mae_on_mini_test)\n",
    "\n",
    "ss_res_mini_test = np.sum((y_test - predictions_on_test)** 2)\n",
    "ss_tot_mini_test = np.sum((y_test - np.mean(y_test))**2)\n",
    "r2_score_on_mini_test = 1 - (ss_res_mini_test / ss_tot_mini_test)\n",
    "print(\"R^2 Score on test set with Mini-Batch GD:\", r2_score_on_mini_test)   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
