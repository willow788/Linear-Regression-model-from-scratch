"""
Main training script for Version 3.1

üéâ THE COMPLETE FIX! üéâ

This version FINALLY combines all the best features: 
‚úÖ Train/test split (proper evaluation)
‚úÖ Target normalization (numerical stability)
‚úÖ Separate bias term (cleaner implementation)
‚úÖ Excellent results (R¬≤ ~ 0.90 on test set)
"""

import numpy as np
from data_preprocessing import load_and_split_data
from linear_regression import LinearRegression
from metrics import (evaluate_model, compare_train_test_performance, 
                     print_model_summary)


def main():
    """Train and evaluate the linear regression model."""
    
    print("="*60)
    print(" " * 15 + "VERSION 3.1")
    print(" " * 8 + "üéâ THE COMPLETE FIX!  üéâ")
    print("="*60)
    
    # Load and prepare data with train/test split AND normalization
    print("\nüìÅ Loading and preparing data...")
    X_train, X_test, y_train, y_test, X_mean, X_std, y_mean, y_std = load_and_split_data(
        'Advertising.csv',
        test_size=0.2,
        random_state=42
    )
    
    print(f"\n‚úì Training set size: {X_train.shape[0]} samples")
    print(f"‚úì Test set size: {X_test.shape[0]} samples")
    print(f"‚úì Features: {X_train.shape[1]}")
    print(f"‚úì Features normalized using training statistics")
    print(f"‚úì Target normalized using training statistics")
    print(f"  - y_train mean: {y_train.mean():.6f}, std: {y_train.std():.6f}")
    print(f"  - y_test mean: {y_test.mean():.6f}, std: {y_test.std():.6f}")
    
    # Initialize and train model
    print("\n" + "="*60)
    print("üöÄ Training model...")
    print("="*60)
    print("Hyperparameters:  learning_rate=0.02, iterations=50000")
    print("Note: Using separate bias term (not concatenated to weights)")
    print()
    
    model = LinearRegression(learn_rate=0.02, iter=50000)
    model.fit(X_train, y_train)
    
    # Make predictions on both train and test sets
    print("\nüìä Making predictions...")
    train_predictions = model.predict(X_train)
    test_predictions = model.predict(X_test)
    
    # Evaluate on training set
    print("\n" + "="*60)
    print("üìà TRAINING SET EVALUATION")
    print("="*60)
    train_metrics = evaluate_model(y_train, train_predictions, "Training")
    
    # Evaluate on test set
    print("\n" + "="*60)
    print("üìä TEST SET EVALUATION (Most Important! )")
    print("="*60)
    test_metrics = evaluate_model(y_test, test_predictions, "Test")
    
    # Compare performance
    compare_train_test_performance(train_metrics, test_metrics)
    
    # Print comprehensive summary
    print_model_summary(model, train_metrics, test_metrics)
    
    # Final analysis
    print("\n" + "="*60)
    print("WHAT MADE THIS WORK")
    print("="*60)
    print("\n‚úÖ Train/test split (from Version 3)")
    print("   ‚Üí Proper evaluation on unseen data")
    print("\n‚úÖ Target normalization (from Version 2.3)")
    print("   ‚Üí Numerical stability in gradient descent")
    print("\n‚úÖ Separate bias term")
    print("   ‚Üí Cleaner, more interpretable implementation")
    print("\n‚úÖ Proper use of training statistics")
    print("   ‚Üí No data leakage from test set")
    
    print("\n" + "="*60)
    print("RESULTS SUMMARY")
    print("="*60)
    print(f"üéØ Test R¬≤ Score: {test_metrics['r2']:.4f}")
    print(f"   Model explains {test_metrics['r2']*100:.2f}% of variance in unseen data")
    print(f"\nüéØ Train R¬≤ Score: {train_metrics['r2']:. 4f}")
    print(f"   Similar to test score - good generalization!")
    
    if test_metrics['r2'] > 0.89:
        print("\nüèÜ EXCELLENT! This is a well-performing model!")
    
    print("\n" + "="*60)
    print("NEXT STEPS")
    print("="*60)
    print("Future versions will explore:")
    print("- Version 4: Multiple gradient descent methods (SGD, mini-batch)")
    print("- Version 5: L2 regularization (Ridge)")
    print("- Version 6: L1 regularization (Lasso)")
    print("="*60)
    
    return model, train_metrics, test_metrics


if __name__ == "__main__":
    model, train_metrics, test_metrics = main()
